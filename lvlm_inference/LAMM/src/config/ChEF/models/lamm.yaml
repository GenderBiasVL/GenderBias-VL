model_name: LAMM
model_path: openlamm/lamm_13b_lora32_186k/pytorch_model.pt
llm_ckpt_path: openlamm/llm_13b_v0
encoder_ckpt_path: openai/clip-vit-large-patch14 # has no effect actually
task_type: noraml
encoder_pretrain: clip
vision_type: image
vision_feature_type: local
vision_output_layer: -2
num_vision_token: 256
lora_r: 32
lora_alpha: 32
lora_dropout: 0.1
lora_target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj']
max_tgt_len: 1024
stage: 2